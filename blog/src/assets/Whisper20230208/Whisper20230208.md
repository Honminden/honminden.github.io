# 使用Whisper开源模型提取会议记录

过去一年多时间各种会议的录屏多达80G，想梳理之前的会议都要从几小时的视频里找信息，非常麻烦，如果能够自动生成会议记录，后面速览会议内容或者检索关键词会轻松很多。

很多语音识别服务收费或者只能转换一小段，转大段视频的开销没法想象，因此对于有显卡且要求不高的人来说不如用开源模型自己做。笔者使用的Whisper是2022年9月OpenAI开源的语音识别模型，无需调整可以直接用于中文识别，十分方便。

github链接：[openai/whisper](https://github.com/openai/whisper)

## 代码编写

首先需要根据官方指南进行环境配置，安装相关python库并下载配置好ffmpeg。如果使用显卡，则需要提前安装好cuda并最好安装相应版本的pytorch

在导入模型时有两个问题：

1. 选择什么规模的模型。笔者尝试使用tiny发现效果很差，而large效果较好，因此虽然对显存要求很高也最好直接使用large。笔者目前使用的模型版本是2022年12月发布的large-v2，估计开发人员将会继续更新large模型，可直接选择最新版本。
2. 模型存储位置。large-v2模型文件大小为2.87GB，建议像视频一样存储到容量有空余的硬盘上，可以通过download_root参数设置存储目录。

```python
class Audio2Text():
    def __init__(self, model_size='large', device = torch.device('cuda:0')):
        self.model_size = model_size
        self.device = device
        self.model = whisper.load_model(model_size, device=device, download_root=DOWNLOAD_ROOT)
```

在处理视频部分，由于模型默认每次处理30秒视频，需要首先将视频读取为numpy数组，再循环读取30秒片段转为文字，不足30秒的部分进行补齐。

另外要注意输出文字为繁体中文，可以通过zhconv库统一转换为简体。

此外本文使用tqdm库添加进度条功能，方便查看视频处理进度。

```python
from whisper.audio import CHUNK_LENGTH, N_SAMPLES
from zhconv import convert
```
```python
    def _audio2text(self, path, use_tqdm=True, use_zhconv=True):
        audio = whisper.load_audio(path)
        texts = list()
        end = len(audio) // N_SAMPLES + 1
        if use_tqdm:
            rng = tqdm.tqdm(range(end))
        else:
            rng = range(end)
        for idx in rng:
            clip = audio[idx * N_SAMPLES:min(len(audio), (idx + 1) * N_SAMPLES)]
            clip = whisper.pad_or_trim(clip)
            mel = whisper.log_mel_spectrogram(clip).to(self.model.device)

            options = whisper.DecodingOptions()
            result = whisper.decode(self.model, mel, options)
            text = result.text
            if use_zhconv:
                text = convert(text, 'zh-hans')
            texts.append(text)

        return texts
```

输出部分将每30秒的文字打上时间戳，输出为一行文本，使用datetime实现。

```python
    def _write_to_file(self, texts, path):
        time = datetime.timedelta()
        with open(path, 'w') as f:
            for text in texts:
                f.write(str(time))
                f.write(text)
                f.write('\n')
                time += datetime.timedelta(seconds=CHUNK_LENGTH)
```

最后添加上处理单个视频与整个目录下视频的方法。

```python
    def transform_file(self, path, use_tqdm=True, use_zhconv=True):
        texts = self._audio2text(path, use_tqdm=use_tqdm, use_zhconv=use_zhconv)
        self._write_to_file(texts, path="".join((path, TEXT_POSTFIX)))
    
    def transform_dir(self, path, use_tqdm=True, use_zhconv=True):
        if use_tqdm:
            rng = tqdm.tqdm(os.listdir(path))
        else:
            rng = os.listdir(path)
        for file in rng:
            if not file.endswith(POSTFIX_EXCLUSIVE):
                self.transform_file(os.path.join(path, file), use_tqdm=False, use_zhconv=use_zhconv)
```

调用起来比较简单，笔者倾向于使用jupyter notebook进行调用，比较轻便。

```python
a2t = Audio2Text()
a2t.transform_dir(path)
```

## 识别效果

下面展示一下实际转换的效果，输出大体上相当准确，只是没法很好准确识别说话间隔和专用名词。
```
0:00:00喂喂,听得到吗?听得到听得到,但是那个东西还没有转移到你阿波罗已经安上去了是吧?喂行吧,那我这边听不太清,你打字或者是啥的行吗?或者你直接发微信发给我
0:00:30然后后面你看一下FastLeo里面的一些原理吧你那些原理性的那些东西你先推一遍你帮我推一遍然后整理一个PPT可以吗最近推倒的话
0:01:00最好能有啊哦对对对现在听得到吗能听到能听到你就先整理一个那个Fast Leo的PPT给我吧然后那个转移那个事估计你可能经验不是很多反正我最近我也在搞因为我这边
0:01:30你那边的进度,所以我这边在搞你帮我准备一个PPT吧,好吧846的那个,对吧什么,846的那个原理,原理性的一个PPT准备的稍微详细一点里边的,那种数学原理性的啊,就是数学的,数学的数学,就是数学推导是吗
0:02:00你把那套东西怎么用的,包括怎么搞的,你帮我整理一下,可以吗?好的,好的。
0:02:30所以到时候我们一步一步走,我这边把Rose截了之后再联系你。你先把FastLio的PPT抓紧时间帮我整理一下,谢谢。
```

当然也会出现一些比较诡异的情况，比如突然识别坏了一整个30秒小段，但下一段又恢复到很准确了。

```
0:01:30嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯,嗯
0:02:00然后后面的话就是嗯后面的话呃就是像这个地方会稍微降了一点都他他他不是最好的但是就是他这是那个多尺度的一个啊就是弄出来是这样的然后之前不是多尺度的情况下的话就是这两个都是可以超过比如像超过这个比如说这个超过这个可以超过0.9左右
```

总之用于速览会议内容已经非常靠谱，少量丢失的信息可以打开视频到对应段落去听；而用于关键词检索可能不太理想，需要配合模糊匹配等方法。

## 资源消耗与效率

large模型对显存要求比较高，笔者一张3080卡显存几乎吃满（~10G），运行时就不能开别的游戏或炼丹了。

识别速度还算比较快，总长12小时的视频花费了1小时46分钟，平均视频每小时8.8分钟，对于一般的会议时长完全够迅速出记录。

## 后续改进

一般使用基本不需要动模型了，也就是改改代码，可以考虑的改进方向主要有实时转换、配合查询等，有条件的话可以压缩下模型、降一下视频采样率实现更快速的识别。